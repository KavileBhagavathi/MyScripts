### Starting TaskPrologue of job 1368443 on f1153 at Thu Jun 27 08:14:11 CEST 2024
#   SLURM_JOB_NODELIST=f1153
#   SLURM_JOB_NUM_NODES=1
#   SLURM_NTASKS=1
#   SLURM_NPROCS=1
#   SLURM_TASKS_PER_NODE=1
#   SLURM_JOB_CPUS_PER_NODE=72
#   SLURM_EXPORT_ENV=NONE
Running on cores 0-71 with governor powersave
### Finished TaskPrologue
Running benchmark for 1 threads
Time: 65.132861
Running benchmark for 2 threads
Time: 38.051945
Running benchmark for 3 threads
Time: 26.511511
Running benchmark for 4 threads
Time: 18.438076
Running benchmark for 5 threads
Time: 15.518845
Running benchmark for 6 threads
Time: 13.848745
Running benchmark for 7 threads
Time: 11.284640
Running benchmark for 8 threads
Time: 11.006786
Running benchmark for 9 threads
Time: 8.660626
Running benchmark for 10 threads
Time: 8.660087
Running benchmark for 11 threads
Time: 8.660755
Running benchmark for 12 threads
Time: 7.095444
Running benchmark for 13 threads
Time: 5.975404
Running benchmark for 14 threads
Time: 5.852520
Running benchmark for 15 threads
Time: 5.890259
Running benchmark for 16 threads
Time: 5.853490
Running benchmark for 17 threads
Time: 5.856343
Running benchmark for 18 threads
Time: 5.848319
Running benchmark for 19 threads
Time: 5.182476
Running benchmark for 20 threads
Time: 4.897365
Running benchmark for 21 threads
Time: 4.889258
Running benchmark for 22 threads
Time: 4.301472
Running benchmark for 23 threads
Time: 4.051028
Running benchmark for 24 threads
Time: 4.016574
Running benchmark for 25 threads
Time: 4.016349
Running benchmark for 26 threads
Time: 3.404394
Running benchmark for 27 threads
Time: 3.246168
Running benchmark for 28 threads
Time: 3.242845
Running benchmark for 29 threads
Time: 3.245772
Running benchmark for 30 threads
Time: 2.945541
Running benchmark for 31 threads
Time: 2.942785
Running benchmark for 32 threads
Time: 2.933815
Running benchmark for 33 threads
Time: 2.946406
Running benchmark for 34 threads
Time: 2.948779
Running benchmark for 35 threads
Time: 2.937533
Running benchmark for 36 threads
Time: 2.945722
Running benchmark for 37 threads
Time: 2.957122
Running benchmark for 38 threads
Time: 2.940658
Running benchmark for 39 threads
Time: 2.954860
Running benchmark for 40 threads
Time: 2.937981
Running benchmark for 41 threads
Time: 2.936416
Running benchmark for 42 threads
Time: 2.939171
Running benchmark for 43 threads
Time: 2.945535
Running benchmark for 44 threads
Time: 2.938556
Running benchmark for 45 threads
Time: 2.941913
Running benchmark for 46 threads
Time: 2.945002
Running benchmark for 47 threads
Time: 2.949119
Running benchmark for 48 threads
Time: 2.936540
Running benchmark for 49 threads
Time: 2.937363
Running benchmark for 50 threads
Time: 2.961886
Running benchmark for 51 threads
Time: 2.948733
Running benchmark for 52 threads
Time: 2.953676
Running benchmark for 53 threads
Time: 2.940768
Running benchmark for 54 threads
Time: 2.948739
Running benchmark for 55 threads
Time: 2.949484
Running benchmark for 56 threads
Time: 2.948142
Running benchmark for 57 threads
Time: 2.939473
Running benchmark for 58 threads
Time: 2.941207
Running benchmark for 59 threads
Time: 2.939896
Running benchmark for 60 threads
Time: 2.950076
Running benchmark for 61 threads
Time: 2.943334
Running benchmark for 62 threads
Time: 2.950921
Running benchmark for 63 threads
Time: 2.942211
Running benchmark for 64 threads
Time: 2.943119
Running benchmark for 65 threads
Time: 2.940069
Running benchmark for 66 threads
Time: 2.941982
Running benchmark for 67 threads
Time: 2.941891
Running benchmark for 68 threads
Time: 2.954527
Running benchmark for 69 threads
Time: 2.953587
Running benchmark for 70 threads
Time: 2.939924
Running benchmark for 71 threads
Time: 2.948886
Running benchmark for 72 threads
Time: 2.950377
  adding: raytrace500_core1.txt (deflated 2%)
  adding: raytrace500_core10.txt (deflated 3%)
  adding: raytrace500_core11.txt (deflated 3%)
  adding: raytrace500_core12.txt (deflated 3%)
  adding: raytrace500_core13.txt (deflated 3%)
  adding: raytrace500_core14.txt (deflated 3%)
  adding: raytrace500_core15.txt (deflated 3%)
  adding: raytrace500_core16.txt (deflated 3%)
  adding: raytrace500_core17.txt (deflated 3%)
  adding: raytrace500_core18.txt (deflated 3%)
  adding: raytrace500_core19.txt (deflated 3%)
  adding: raytrace500_core2.txt (deflated 3%)
  adding: raytrace500_core20.txt (deflated 3%)
  adding: raytrace500_core21.txt (deflated 3%)
  adding: raytrace500_core22.txt (deflated 3%)
  adding: raytrace500_core23.txt (deflated 3%)
  adding: raytrace500_core24.txt (deflated 3%)
  adding: raytrace500_core25.txt (deflated 3%)
  adding: raytrace500_core26.txt (deflated 3%)
  adding: raytrace500_core27.txt (deflated 3%)
  adding: raytrace500_core28.txt (deflated 5%)
  adding: raytrace500_core29.txt (deflated 3%)
  adding: raytrace500_core3.txt (deflated 3%)
  adding: raytrace500_core30.txt (deflated 3%)
  adding: raytrace500_core31.txt (deflated 3%)
  adding: raytrace500_core32.txt (deflated 3%)
  adding: raytrace500_core33.txt (deflated 3%)
  adding: raytrace500_core34.txt (deflated 3%)
  adding: raytrace500_core35.txt (deflated 3%)
  adding: raytrace500_core36.txt (deflated 3%)
  adding: raytrace500_core37.txt (deflated 3%)
  adding: raytrace500_core38.txt (deflated 3%)
  adding: raytrace500_core39.txt (deflated 3%)
  adding: raytrace500_core4.txt (deflated 3%)
  adding: raytrace500_core40.txt (deflated 3%)
  adding: raytrace500_core41.txt (deflated 3%)
  adding: raytrace500_core42.txt (deflated 3%)
  adding: raytrace500_core43.txt (deflated 3%)
  adding: raytrace500_core44.txt (deflated 3%)
  adding: raytrace500_core45.txt (deflated 3%)
  adding: raytrace500_core46.txt (deflated 5%)
  adding: raytrace500_core47.txt (deflated 3%)
  adding: raytrace500_core48.txt (deflated 3%)
  adding: raytrace500_core49.txt (deflated 3%)
  adding: raytrace500_core5.txt (deflated 3%)
  adding: raytrace500_core50.txt (deflated 3%)
  adding: raytrace500_core51.txt (deflated 3%)
  adding: raytrace500_core52.txt (deflated 3%)
  adding: raytrace500_core53.txt (deflated 3%)
  adding: raytrace500_core54.txt (deflated 3%)
  adding: raytrace500_core55.txt (deflated 3%)
  adding: raytrace500_core56.txt (deflated 3%)
  adding: raytrace500_core57.txt (deflated 3%)
  adding: raytrace500_core58.txt (deflated 3%)
  adding: raytrace500_core59.txt (deflated 3%)
  adding: raytrace500_core6.txt (deflated 3%)
  adding: raytrace500_core60.txt (deflated 3%)
  adding: raytrace500_core61.txt (deflated 3%)
  adding: raytrace500_core62.txt (deflated 3%)
  adding: raytrace500_core63.txt (deflated 3%)
  adding: raytrace500_core64.txt (deflated 3%)
  adding: raytrace500_core65.txt (deflated 3%)
  adding: raytrace500_core66.txt (deflated 3%)
  adding: raytrace500_core67.txt (deflated 3%)
  adding: raytrace500_core68.txt (deflated 3%)
  adding: raytrace500_core69.txt (deflated 3%)
  adding: raytrace500_core7.txt (deflated 3%)
  adding: raytrace500_core70.txt (deflated 3%)
  adding: raytrace500_core71.txt (deflated 5%)
  adding: raytrace500_core72.txt (deflated 3%)
  adding: raytrace500_core8.txt (deflated 3%)
  adding: raytrace500_core9.txt (deflated 3%)
=== JOB_STATISTICS ===
=== current date     : Thu Jun 27 08:29:40 CEST 2024
= Job-ID             : 1368443 on fritz
= Job-Name           : raytrace
= Job-Command        : /home/hpc/ptfs/ptfs288h/ptfs/assignment7/parallelray/job.sh
= Initial workdir    : /home/hpc/ptfs/ptfs288h/ptfs/assignment7/parallelray
= Queue/Partition    : singlenode
= Slurm account      : ptfs with QOS=ptfs
= Requested resources:  for 01:00:00
= Elapsed runtime    : 00:15:31
= Total RAM usage    : 0.2 GiB 
= Node list          : f1153
= Subm/Elig/Start/End: 2024-06-27T08:14:08 / 2024-06-27T08:14:08 / 2024-06-27T08:14:08 / 2024-06-27T08:29:39
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc         3036.6M   104.9G   209.7G        N/A   9,282      500K   1,000K        N/A    
    /lustre              4.0K     0.0K     0.0K        N/A       1       80K     250K        N/A    
======================
